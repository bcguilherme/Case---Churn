{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bcguilherme/Case---Churn/blob/main/Case_Churn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Load the dataset from an Excel file\n",
        "data = pd.read_excel(\"/content/churn_data.xlsx\")\n",
        "\n",
        "# Exploratory data analysis\n",
        "data.describe()\n",
        "\n",
        "# Check for missing values in the dataset\n",
        "missing_values = data.isnull().sum()\n",
        "print(missing_values)\n",
        "data.info()\n",
        "\n",
        "# Remove rows with missing values\n",
        "data = data.dropna()\n",
        "\n",
        "# Encode class labels ('Churn') using LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "data['Churn'] = label_encoder.fit_transform(data['Churn'])\n",
        "\n",
        "# Split the data into features (X) and labels (y)\n",
        "X = data[['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']]\n",
        "y = data['Churn']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and calculate performance metrics for Logistic Regression\n",
        "lr_predictions = lr_model.predict(X_test)\n",
        "lr_probabilities = lr_model.predict_proba(X_test)[:, 1]\n",
        "accuracy = accuracy_score(y_test, lr_predictions)\n",
        "precision = precision_score(y_test, lr_predictions)\n",
        "recall = recall_score(y_test, lr_predictions)\n",
        "f1 = f1_score(y_test, lr_predictions)\n",
        "roc_auc = roc_auc_score(y_test, lr_probabilities)\n",
        "\n",
        "# Display metrics for Logistic Regression\n",
        "print(\"Logistic Regression\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n",
        "print(f\"AUC-ROC: {roc_auc}\")\n",
        "\n",
        "# Train a RandomForestClassifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and calculate performance metrics for RandomForestClassifier\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, rf_predictions)\n",
        "precision_rf = precision_score(y_test, rf_predictions)\n",
        "recall_rf = recall_score(y_test, rf_predictions)\n",
        "f1_rf = f1_score(y_test, rf_predictions)\n",
        "\n",
        "# Display metrics for RandomForestClassifier\n",
        "print(\"\\nRandom Forest\")\n",
        "print(f\"Accuracy: {accuracy_rf}\")\n",
        "print(f\"Precision: {precision_rf}\")\n",
        "print(f\"Recall: {recall_rf}\")\n",
        "print(f\"F1-Score: {f1_rf}\")\n",
        "\n",
        "# Train an XGBoost model\n",
        "xgb_model = XGBClassifier()\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and calculate performance metrics for XGBoost\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "xgb_probabilities = xgb_model.predict_proba(X_test)[:, 1]\n",
        "accuracy_xgb = accuracy_score(y_test, xgb_predictions)\n",
        "precision_xgb = precision_score(y_test, xgb_predictions)\n",
        "recall_xgb = recall_score(y_test, xgb_predictions)\n",
        "f1_xgb = f1_score(y_test, xgb_predictions)\n",
        "roc_auc_xgb = roc_auc_score(y_test, xgb_probabilities)\n",
        "\n",
        "# Display metrics for XGBoost\n",
        "print(\"\\nXGBoost\")\n",
        "print(f\"Accuracy: {accuracy_xgb}\")\n",
        "print(f\"Precision: {precision_xgb}\")\n",
        "print(f\"Recall: {recall_xgb}\")\n",
        "print(f\"F1-Score: {f1_xgb}\")\n",
        "print(f\"AUC-ROC: {roc_auc_xgb}\")\n",
        "\n",
        "# Hyperparameter tuning for RandomForestClassifier using GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Train RandomForestClassifier with best hyperparameters\n",
        "best_rf_model = RandomForestClassifier(random_state=42, **best_params)\n",
        "best_rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and calculate performance metrics for tuned RandomForestClassifier\n",
        "best_rf_predictions = best_rf_model.predict(X_test)\n",
        "accuracy_best_rf = accuracy_score(y_test, best_rf_predictions)\n",
        "precision_best_rf = precision_score(y_test, best_rf_predictions)\n",
        "recall_best_rf = recall_score(y_test, best_rf_predictions)\n",
        "f1_best_rf = f1_score(y_test, best_rf_predictions)\n",
        "\n",
        "# Display metrics for tuned RandomForestClassifier\n",
        "print(\"\\nTuned Random Forest\")\n",
        "print(f\"Accuracy: {accuracy_best_rf}\")\n",
        "print(f\"Precision: {precision_best_rf}\")\n",
        "print(f\"Recall: {recall_best_rf}\")\n",
        "print(f\"F1-Score: {f1_best_rf}\")\n",
        "\n",
        "# Hyperparameter tuning for RandomForestClassifier using GridSearchCV\n",
        "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Train RandomForestClassifier with best hyperparameters\n",
        "best_rf_model = RandomForestClassifier(random_state=42, **best_params)\n",
        "best_rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and calculate performance metrics for tuned RandomForestClassifier\n",
        "best_rf_predictions = best_rf_model.predict(X_test)\n",
        "accuracy_best_rf = accuracy_score(y_test, best_rf_predictions)\n",
        "precision_best_rf = precision_score(y_test, best_rf_predictions)\n",
        "recall_best_rf = recall_score(y_test, best_rf_predictions)\n",
        "f1_best_rf = f1_score(y_test, best_rf_predictions)\n",
        "\n",
        "# Display metrics for tuned RandomForestClassifier\n",
        "print(\"\\nTuned Random Forest\")\n",
        "print(f\"Accuracy: {accuracy_best_rf}\")\n",
        "print(f\"Precision: {precision_best_rf}\")\n",
        "print(f\"Recall: {recall_best_rf}\")\n",
        "print(f\"F1-Score: {f1_best_rf}\")\n",
        "\n",
        "# Train an XGBoost model with hyperparameter tuning\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "}\n",
        "grid_search_xgb = GridSearchCV(xgb_model, param_grid_xgb, cv=5, scoring='accuracy')\n",
        "grid_search_xgb.fit(X_train, y_train)\n",
        "best_params_xgb = grid_search_xgb.best_params_\n",
        "\n",
        "# Train XGBoost model with best hyperparameters\n",
        "best_xgb_model = XGBClassifier(**best_params_xgb)\n",
        "best_xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n"
      ],
      "metadata": {
        "id": "kHOlx2d2dgB-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}